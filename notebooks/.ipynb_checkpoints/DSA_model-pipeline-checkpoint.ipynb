{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.data_loader as data_loader\n",
    "from pathlib import Path\n",
    "import utils.model_loader as model_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = data_loader.get_data('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = Path(Path.cwd().parents[0], 'data', 'movielens', 'ml-latest-small')\n",
    "data_raw = data_loader.get_data('ratings.csv', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVD, NMF\n",
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "from surprise.prediction_algorithms.algo_base import AlgoBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evalute_model_pipeline(model_class: AlgoBase, dataset: str = 'ml-100k', \n",
    "                                     from_surprise: bool = True, \n",
    "                                     test_size: float = 0.2,\n",
    "                                     model_kwargs: dict = {}) -> (AlgoBase, dict):\n",
    "    data = data_loader.get_data(dataset, from_surprise)\n",
    "    train_set, test_set = train_test_split(data, test_size, random_state=42)\n",
    "    model = model_loader.get_trained_model(model_class, train_set, model_kwargs)\n",
    "    metrics_dict = model_loader.evaluate_model(model, test_set)\n",
    "    return model, metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RMSE': 0.980150596704479, 'MAE': 0.980150596704479}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model, metrics_dict = train_and_evalute_model_pipeline(KNNBasic)\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RMSE': 1.041104054968961, 'MAE': 1.041104054968961}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_kwargs = {'sim_options': {'user_based': False, 'name': 'pearson'}}\n",
    "my_model, metrics_dict = train_and_evalute_model_pipeline(KNNBasic, model_kwargs=model_kwargs)\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RMSE': 0.9360802939362804, 'MAE': 0.9360802939362804}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model, metrics_dict = train_and_evalute_model_pipeline(SVD)\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNN user based with cosine similarity': {'RMSE': 0.980150596704479,\n",
       "  'MAE': 0.980150596704479},\n",
       " 'KNN user based with pearson similarity': {'RMSE': 0.980150596704479,\n",
       "  'MAE': 0.980150596704479},\n",
       " 'KNN item based with cosine similarity': {'RMSE': 0.980150596704479,\n",
       "  'MAE': 0.980150596704479},\n",
       " 'KNN item based with pearson similarity': {'RMSE': 0.980150596704479,\n",
       "  'MAE': 0.980150596704479},\n",
       " 'SVD': {'RMSE': 0.9345987396157499, 'MAE': 0.9345987396157499},\n",
       " 'NMF': {'RMSE': 0.9624799306524018, 'MAE': 0.9624799306524018}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_dict = {}\n",
    "\n",
    "\n",
    "model_dict_list = [\n",
    "    {\n",
    "        'model_name' : 'KNN user based with cosine similarity',\n",
    "        'model_class' : KNNBasic,\n",
    "        'model_kwargs' : {'user_based': True, 'name': 'cosine'}\n",
    "    },\n",
    "    {\n",
    "        'model_name' : 'KNN user based with pearson similarity',\n",
    "        'model_class' : KNNBasic,\n",
    "        'model_kwargs' : {'user_based': True, 'name': 'pearson'}\n",
    "    },\n",
    "    {\n",
    "        'model_name' : 'KNN item based with cosine similarity',\n",
    "        'model_class' : KNNBasic,\n",
    "        'model_kwargs' : {'user_based': False, 'name': 'cosine'}\n",
    "    },\n",
    "    {\n",
    "        'model_name' : 'KNN item based with pearson similarity',\n",
    "        'model_class' : KNNBasic,\n",
    "        'model_kwargs' : {'user_based': False, 'name': 'pearson'}\n",
    "    },\n",
    "    {\n",
    "        'model_name' : 'SVD',\n",
    "        'model_class' : SVD\n",
    "    },\n",
    "    {\n",
    "        'model_name' : 'NMF',\n",
    "        'model_class' : NMF\n",
    "    },\n",
    "    \n",
    "]\n",
    "\n",
    "for model_dict in model_dict_list:\n",
    "    model, metrics_dict = train_and_evalute_model_pipeline(\n",
    "        model_dict['model_class'], model_kwargs = model_dict.get('model_kwargs', {}))\n",
    "    benchmark_dict[model_dict['model_name']] = metrics_dict\n",
    "    model_dict['fitted_model'] = model\n",
    "    \n",
    "\n",
    "benchmark_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>178</td>\n",
       "      <td>Love &amp; Human Remains (1993)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>187</td>\n",
       "      <td>Party Girl (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>318</td>\n",
       "      <td>Shawshank Redemption, The (1994)</td>\n",
       "      <td>Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>408</td>\n",
       "      <td>8 Seconds (1994)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>519</td>\n",
       "      <td>RoboCop 3 (1993)</td>\n",
       "      <td>Action|Crime|Drama|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>923</td>\n",
       "      <td>Citizen Kane (1941)</td>\n",
       "      <td>Drama|Mystery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     movieId                             title  \\\n",
       "150      178       Love & Human Remains (1993)   \n",
       "158      187                 Party Girl (1995)   \n",
       "277      318  Shawshank Redemption, The (1994)   \n",
       "353      408                  8 Seconds (1994)   \n",
       "454      519                  RoboCop 3 (1993)   \n",
       "705      923               Citizen Kane (1941)   \n",
       "\n",
       "                                 genres  \n",
       "150                        Comedy|Drama  \n",
       "158                              Comedy  \n",
       "277                         Crime|Drama  \n",
       "353                               Drama  \n",
       "454  Action|Crime|Drama|Sci-Fi|Thriller  \n",
       "705                       Drama|Mystery  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from surprise.dump import dump, load\n",
    "\n",
    "data_dir = Path(Path.cwd().parents[0], 'data', 'movielens', 'ml-latest-small')\n",
    "def get_movies_data(data_dir):\n",
    "    movies = pd.read_csv(Path(data_dir, 'movies.csv'))\n",
    "    return movies\n",
    "\n",
    "# def get_predictions(model, user, movies, k):\n",
    "#     movies['user'] = user\n",
    "#     preds = movies.apply(lambda x: model.predict(x[0], x[-1]), 1, result_type='expand')\n",
    "#     idx = preds[3].argsort()[:k]\n",
    "#     ids = preds.iloc[idx, 0]\n",
    "#     mvs = movies.movieId.isin(ids)\n",
    "#     return movies.loc[mvs, ['title', 'genres']]\n",
    "\n",
    "def get_movie_details(preds, movies):\n",
    "#     movies['user'] = user\n",
    "#     preds = movies.apply(lambda x: model.predict(x[0], x[-1]), 1, result_type='expand')\n",
    "#     idx = preds[3].argsort()[:k]\n",
    "    ids = [int(x[0]) for x in preds]\n",
    "    mvs = movies.movieId.isin(ids)\n",
    "    return movies.loc[mvs, ['movieId', 'title', 'genres']]\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "    \n",
    "\n",
    "    \n",
    "def get_user_recommendation(model: AlgoBase, user_id: int, k: int, data\n",
    "                           ) -> pd.DataFrame:\n",
    "    \"\"\"Makes movie recommendations a user.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        model : AlgoBase\n",
    "            A trained surprise model\n",
    "        user_id : int\n",
    "            The user for whom the recommendation will be done.\n",
    "        k : int\n",
    "            The number of items to recommend.\n",
    "        data : FIXME\n",
    "            The data needed to do the recommendation.\n",
    "        movies : pandas.DataFrame\n",
    "            The dataframe containing the movies metadata (title, genre, etc)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.Dataframe\n",
    "        A dataframe with the k movies that will be recommended the user. The dataframe should have the following\n",
    "        columns (movie_name : str, movie_genre : str, predicted_rating : float, true_rating : float)\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    - You should create other functions that are used in this one and not put all the code in the same function.\n",
    "        For example to create the final dataframe, instead of implemented all the code\n",
    "        in this function (get_user_recommendation), you can create a new one (create_recommendation_dataframe)\n",
    "        that will be called in this function.\n",
    "    - You can add other arguments to the function if you need to.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        predictions, model = load('model.prod')\n",
    "    except:\n",
    "        trainset = data.build_full_trainset()\n",
    "        testset = trainset.build_anti_testset()\n",
    "        model = model_loader.get_trained_model(model, trainset)\n",
    "        predictions = model.test(testset)\n",
    "        dump('model.prod', predictions, model)\n",
    "    top_n = get_top_n(predictions, n=k)\n",
    "    movies = get_movies_data(data_dir)\n",
    "#     details = get_movie_details(top_n[user_id], movies)\n",
    "#     df = pd.DataFrame(top_n, columns=['Id', 'Rating'])\n",
    "    \n",
    "    return get_movie_details(top_n[user_id], movies)\n",
    "\n",
    "recommendations = get_user_recommendation(SVD, '196', 10, data_raw)\n",
    "display(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epita_recsys",
   "language": "python",
   "name": "epita_recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
