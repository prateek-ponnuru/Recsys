{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.data_loader as data_loader\n",
    "from pathlib import Path\n",
    "import utils.model_loader as model_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = data_loader.get_data('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = Path(Path.cwd().parents[0], 'data', 'movielens', 'ml-latest-small')\n",
    "data_raw = data_loader.get_data('ratings.csv', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVD, NMF\n",
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "from surprise.prediction_algorithms.algo_base import AlgoBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evalute_model_pipeline(model_class: AlgoBase, dataset: str = 'ml-100k', \n",
    "                                     from_surprise: bool = True, \n",
    "                                     test_size: float = 0.2,\n",
    "                                     model_kwargs: dict = {}) -> (AlgoBase, dict):\n",
    "    data = data_loader.get_data(dataset, from_surprise)\n",
    "    train_set, test_set = train_test_split(data, test_size, random_state=42)\n",
    "    model = model_loader.get_trained_model(model_class, train_set, model_kwargs)\n",
    "    metrics_dict = model_loader.evaluate_model(model, test_set)\n",
    "    return model, metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RMSE': 0.980150596704479, 'MAE': 0.980150596704479}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model, metrics_dict = train_and_evalute_model_pipeline(KNNBasic)\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RMSE': 1.041104054968961, 'MAE': 1.041104054968961}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_kwargs = {'sim_options': {'user_based': False, 'name': 'pearson'}}\n",
    "my_model, metrics_dict = train_and_evalute_model_pipeline(KNNBasic, model_kwargs=model_kwargs)\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RMSE': 0.9360802939362804, 'MAE': 0.9360802939362804}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model, metrics_dict = train_and_evalute_model_pipeline(SVD)\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNN user based with cosine similarity': {'RMSE': 0.980150596704479,\n",
       "  'MAE': 0.980150596704479},\n",
       " 'KNN user based with pearson similarity': {'RMSE': 0.980150596704479,\n",
       "  'MAE': 0.980150596704479},\n",
       " 'KNN item based with cosine similarity': {'RMSE': 0.980150596704479,\n",
       "  'MAE': 0.980150596704479},\n",
       " 'KNN item based with pearson similarity': {'RMSE': 0.980150596704479,\n",
       "  'MAE': 0.980150596704479},\n",
       " 'SVD': {'RMSE': 0.9345987396157499, 'MAE': 0.9345987396157499},\n",
       " 'NMF': {'RMSE': 0.9624799306524018, 'MAE': 0.9624799306524018}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_dict = {}\n",
    "\n",
    "\n",
    "model_dict_list = [\n",
    "    {\n",
    "        'model_name' : 'KNN user based with cosine similarity',\n",
    "        'model_class' : KNNBasic,\n",
    "        'model_kwargs' : {'user_based': True, 'name': 'cosine'}\n",
    "    },\n",
    "    {\n",
    "        'model_name' : 'KNN user based with pearson similarity',\n",
    "        'model_class' : KNNBasic,\n",
    "        'model_kwargs' : {'user_based': True, 'name': 'pearson'}\n",
    "    },\n",
    "    {\n",
    "        'model_name' : 'KNN item based with cosine similarity',\n",
    "        'model_class' : KNNBasic,\n",
    "        'model_kwargs' : {'user_based': False, 'name': 'cosine'}\n",
    "    },\n",
    "    {\n",
    "        'model_name' : 'KNN item based with pearson similarity',\n",
    "        'model_class' : KNNBasic,\n",
    "        'model_kwargs' : {'user_based': False, 'name': 'pearson'}\n",
    "    },\n",
    "    {\n",
    "        'model_name' : 'SVD',\n",
    "        'model_class' : SVD\n",
    "    },\n",
    "    {\n",
    "        'model_name' : 'NMF',\n",
    "        'model_class' : NMF\n",
    "    },\n",
    "    \n",
    "]\n",
    "\n",
    "for model_dict in model_dict_list:\n",
    "    model, metrics_dict = train_and_evalute_model_pipeline(\n",
    "        model_dict['model_class'], model_kwargs = model_dict.get('model_kwargs', {}))\n",
    "    benchmark_dict[model_dict['model_name']] = metrics_dict\n",
    "    model_dict['fitted_model'] = model\n",
    "    \n",
    "\n",
    "benchmark_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epita_recsys",
   "language": "python",
   "name": "epita_recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
